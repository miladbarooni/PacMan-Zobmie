# Pac-Man vs Zombies: Adversarial Reinforcement Learning

A reinforcement learning implementation featuring Pac-Man battling AI-controlled zombies using temporal difference learning and adversarial training.

![Python](https://img.shields.io/badge/python-3.10+-blue.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)
![Status](https://img.shields.io/badge/status-playable-success.svg)

---

## Overview

This project implements a Pac-Man variant where:
- **Pac-Man** learns to collect vaccines and cure zombies using **cooperative learning** (maximizes reward)
- **Zombies** learn to hunt Pac-Man using **adversarial learning** (minimizes Pac-Man's reward)
- Both agents use **temporal difference learning** with linear function approximation

The game showcases how adversarial training creates intelligent, adaptive opponents that evolve through experience.

### Key Features

âœ… **Playable Terminal Game** - Human vs AI with beautiful Unicode rendering
âœ… **Complete Training System** - Retrain agents from scratch or fine-tune existing weights
âœ… **Adversarial Learning** - Zombies learn to counter Pac-Man's strategies
âœ… **Linear Function Approximation** - Efficient state representation (8 Pac-Man features, 3 Zombie features)
âœ… **Professional Package Structure** - Clean, modular, type-hinted code
âœ… **Comprehensive CLI Tools** - Play, train, analyze with full control

---

## Quick Start

### Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/PacMan-Zombie.git
cd PacMan-Zombie

# Install dependencies
pip install -r requirements.txt
```

**Requirements**: Python 3.10+, NumPy, Colorama

### Play the Game

```bash
# Play as Pac-Man against trained AI zombies
python scripts/play.py

# Show legal moves (helpful for learning)
python scripts/play.py --show-legal-moves

# Watch AI thinking process
python scripts/play.py --show-ai-thinking
```

**Controls**:
- **W/A/S/D** or **Arrow Keys** - Move Pac-Man
- **F** or **Space** - Shoot zombie (2 cells away)
- **Q** - Quit game

### Train Agents

```bash
# Train Pac-Man (10,000 episodes, ~20 minutes)
python scripts/train.py pacman --episodes 10000

# Train Zombie (using trained Pac-Man as opponent)
python scripts/train.py zombie --opponent-weights weights/pacman_weights.json

# Train both sequentially
python scripts/train.py both --episodes 5000
```

See [TRAINING_GUIDE.md](TRAINING_GUIDE.md) for advanced training options.

---

## Game Rules

### Objective

**Pac-Man Wins** if:
1. Collect vaccines (ðŸ’‰) to cure all zombies
2. Reach the exit (ðŸšª) after all zombies are cured

**Pac-Man Loses** if:
- Captured by a zombie (adjacent cell)
- Falls into a pit (âš«)

### Mechanics

| Element | Symbol | Description |
|---------|--------|-------------|
| Pac-Man | ðŸŸ¡ `@` | Player character (you or AI) |
| Zombie | ðŸ§Ÿ `Z` | AI opponents (4 total) |
| Vaccine | ðŸ’‰ `+` | Cures adjacent zombies (+10 points each) |
| Exit | ðŸšª `X` | Victory exit (appears after zombies cleared) |
| Obstacle | â–ˆ `#` | Impassable terrain |
| Pit | âš« `O` | Instant death for Pac-Man, respawn for zombies |

**Special Abilities**:
- **Shooting**: Pac-Man has 3 shots to kill zombies exactly 2 cells away (straight line only)
- **Vaccine Curing**: Pick up vaccine, walk adjacent to zombie to cure it (8 directions including diagonals)
- **Zombie Respawn**: Zombies that fall in pits respawn randomly; Pac-Man dies permanently

See [docs/GAME_RULES.md](docs/GAME_RULES.md) for complete rules.

---

## How It Works

### Reinforcement Learning Algorithm

Both agents use **Temporal Difference (TD) Learning** with linear function approximation:

```
V(s) = wâ‚Â·fâ‚(s) + wâ‚‚Â·fâ‚‚(s) + ... + wâ‚™Â·fâ‚™(s) = w Â· Ï†(s)
```

Where:
- `V(s)` = estimated value of state `s`
- `w` = learned weight vector
- `Ï†(s)` = feature vector extracted from state `s`

**Weight Update Formulas** (the heart of the algorithm):

```python
# Pac-Man (Cooperative Learning)
w â† w + Î± Â· (V_train - V_hat) Â· Ï†(s)

# Zombie (Adversarial Learning)
w â† w - Î± Â· (V_train - V_hat) Â· Ï†(s)  # Note the MINUS!
```

The **minus sign** in zombie training makes zombies learn to **minimize** Pac-Man's value, creating true adversarial behavior.

### Feature Engineering

**Pac-Man Features** (8-dimensional):
1. Distance to exit (when zombies cleared)
2. Shooting opportunity indicator
3. Remaining vaccines count
4. Distance to nearest vaccine
5. Distance to nearest zombie
6. Has vaccine (binary)
7. Distance to obstacles
8. Distance to pit

**Zombie Features** (3-dimensional):
1. Distance to Pac-Man (chase/flee based on vaccine)
2. Distance to pit (avoidance)
3. Distance to obstacles (avoidance)

See [docs/FEATURES.md](docs/FEATURES.md) for detailed feature engineering.

### Training Process

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Initialize: w_pacman, w_zombie (random or loaded)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Episode Loop (e.g., 10,000 episodes)                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  1. Initialize random game board                  â”‚  â”‚
â”‚  â”‚  2. Game Loop (max 1000 steps):                   â”‚  â”‚
â”‚  â”‚     â€¢ Pac-Man selects action (greedy policy)      â”‚  â”‚
â”‚  â”‚     â€¢ Zombies select actions (greedy policy)      â”‚  â”‚
â”‚  â”‚     â€¢ Execute actions                             â”‚  â”‚
â”‚  â”‚     â€¢ Compute V_train (rewards)                   â”‚  â”‚
â”‚  â”‚     â€¢ Update weights (TD learning)                â”‚  â”‚
â”‚  â”‚  3. Track statistics (win rate, steps, etc.)      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Save trained weights (JSON with metadata)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

See [docs/ALGORITHM.md](docs/ALGORITHM.md) for algorithm deep dive.

---

## Project Structure

```
PacMan-Zombie/
â”œâ”€â”€ src/pacman_zombie/           # Core package
â”‚   â”œâ”€â”€ core/                    # Game logic
â”‚   â”‚   â”œâ”€â”€ board.py            # Game state & rules (900+ lines)
â”‚   â”‚   â””â”€â”€ constants.py        # Configuration constants
â”‚   â”œâ”€â”€ agents/                  # AI agents
â”‚   â”‚   â”œâ”€â”€ pacman_agent.py     # Pac-Man greedy policy
â”‚   â”‚   â”œâ”€â”€ zombie_agent.py     # Zombie greedy policy
â”‚   â”‚   â””â”€â”€ features.py         # Feature extraction
â”‚   â”œâ”€â”€ learning/                # Training system
â”‚   â”‚   â”œâ”€â”€ trainer.py          # TD learning trainers
â”‚   â”‚   â””â”€â”€ weights.py          # Weight I/O with metadata
â”‚   â””â”€â”€ ui/                      # User interfaces
â”‚       â””â”€â”€ terminal_renderer.py # ASCII/Unicode renderer
â”‚
â”œâ”€â”€ scripts/                     # CLI tools
â”‚   â”œâ”€â”€ play.py                 # Human vs AI gameplay
â”‚   â”œâ”€â”€ train.py                # Agent training script
â”‚   â””â”€â”€ migrate_weights.py      # Legacy weight converter
â”‚
â”œâ”€â”€ weights/                     # Trained weights (JSON)
â”‚   â”œâ”€â”€ pacman_weights.json     # Trained Pac-Man (8 weights)
â”‚   â””â”€â”€ zombie_weights.json     # Trained Zombie (3 weights)
â”‚
â”œâ”€â”€ docs/                        # Documentation
â”‚   â”œâ”€â”€ ALGORITHM.md            # Learning algorithm details
â”‚   â”œâ”€â”€ FEATURES.md             # Feature engineering guide
â”‚   â””â”€â”€ GAME_RULES.md           # Complete game rules
â”‚
â”œâ”€â”€ tests/                       # Unit tests (future)
â”œâ”€â”€ TRAINING_GUIDE.md           # Training tutorial
â”œâ”€â”€ PLAY_GUIDE.md               # Gameplay guide
â”œâ”€â”€ requirements.txt            # Python dependencies
â””â”€â”€ README.md                   # This file
```

---

## Usage Examples

### Play with Different Options

```bash
# Default: Unicode + colors
python scripts/play.py

# ASCII-only mode (maximum compatibility)
python scripts/play.py --no-unicode --no-colors

# Educational mode (see everything)
python scripts/play.py --show-legal-moves --show-ai-thinking

# Save game for analysis
python scripts/play.py --save-replay my_game.json
```

### Training Workflows

```bash
# Quick test (100 episodes, ~1 minute)
python scripts/train.py pacman --episodes 100

# Full training (10,000 episodes, ~20 minutes)
python scripts/train.py pacman --episodes 10000 --learning-rate 0.01

# Continue training (fine-tuning)
python scripts/train.py pacman \
    --continue-from weights/pacman_weights.json \
    --episodes 5000 \
    --learning-rate 0.001

# Train with reproducible results
python scripts/train.py both --episodes 5000 --seed 42

# Custom opponent weights
python scripts/train.py zombie \
    --opponent-weights weights/custom_pacman.json \
    --output-dir weights/zombie_custom
```

### Programmatic API

```python
from pacman_zombie.core.board import Board
from pacman_zombie.agents import PacmanAgent, ZombieAgent
from pacman_zombie.learning.weights import WeightManager
from pathlib import Path

# Load trained weights
pacman_w, _ = WeightManager.load(Path('weights/pacman_weights.json'))
zombie_w, _ = WeightManager.load(Path('weights/zombie_weights.json'))

# Initialize agents
pacman = PacmanAgent(pacman_w)
zombie = ZombieAgent(zombie_w)

# Create game board
board = Board()

# Game loop
while not board.is_game_over():
    # AI selects actions
    pacman_action = pacman.select_action(board)
    zombie_actions = zombie.select_actions_all_zombies(board)

    # Execute actions
    board.player_action(pacman_action)
    board.zombies_action(zombie_actions)

# Check outcome
if not board.exit_exist() and board.find_zombies_number() == 0:
    print("Pac-Man wins!")
else:
    print("Zombies win!")
```

---

## Documentation

| Document | Description |
|----------|-------------|
| [PLAY_GUIDE.md](PLAY_GUIDE.md) | How to play the game, controls, strategies |
| [TRAINING_GUIDE.md](TRAINING_GUIDE.md) | Complete training tutorial with examples |
| [docs/ALGORITHM.md](docs/ALGORITHM.md) | Deep dive into the learning algorithm |
| [docs/FEATURES.md](docs/FEATURES.md) | Feature engineering and design rationale |
| [docs/GAME_RULES.md](docs/GAME_RULES.md) | Complete game rules and mechanics |

---

## Requirements

### Python Version
- Python 3.10 or higher

### Dependencies

```
numpy>=1.24.0        # Core numerical operations
colorama>=0.4.6      # Terminal colors (cross-platform)
pygame>=2.5.0        # GUI (optional, for future Pygame renderer)
matplotlib>=3.7.0    # Visualization (optional)
tqdm>=4.65.0         # Progress bars (optional but recommended)
pyyaml>=6.0          # Configuration (future)
```

Install all:
```bash
pip install -r requirements.txt
```

Minimal install (play only):
```bash
pip install numpy colorama
```

---

## Performance

**Training Speed** (Apple M1, default settings):
- Pac-Man: ~10,000 episodes in 20 minutes
- Zombie: ~10,000 episodes in 15 minutes (simpler features)

**Typical Training Results**:
- Pac-Man win rate: 30-50% after 10,000 episodes
- Zombie win rate: 40-60% after 10,000 episodes
- Convergence: Noticeable improvement after 2,000-3,000 episodes

**Game Performance**:
- Average game length: 200-500 steps
- Real-time playability: Instant AI decision-making

---

## Technical Highlights

### Code Quality
- âœ… **100% Type Hints** - Full mypy compatibility
- âœ… **Comprehensive Docstrings** - Google-style documentation
- âœ… **Clean Architecture** - Clear separation of concerns
- âœ… **No Code Duplication** - DRY principles throughout
- âœ… **Professional Package** - Proper `src/` layout

### Algorithm Fidelity
- âœ… **Exact Formula Preservation** - Original weight updates maintained
- âœ… **Adversarial Learning** - True min-max game theory
- âœ… **Greedy Policy** - Optimal action selection with random tie-breaking
- âœ… **TD Learning** - Proper temporal difference updates

### User Experience
- âœ… **Cross-Platform** - Works on macOS, Linux, Windows
- âœ… **Beautiful UI** - Unicode emojis with ASCII fallback
- âœ… **Comprehensive CLI** - Full control via command-line
- âœ… **Error Handling** - Graceful failures with helpful messages

---

## Contributing

Contributions welcome! Areas for improvement:

### High Priority
- [ ] Unit tests (pytest framework)
- [ ] Pygame visual renderer (extract from `game.py`)
- [ ] Watch script (AI vs AI spectator mode)
- [ ] Performance profiling and optimization

### Medium Priority
- [ ] Configuration files (YAML)
- [ ] Replay viewer/analyzer
- [ ] Alternative feature sets
- [ ] Different learning algorithms (Q-learning, DQN)

### Low Priority
- [ ] Web-based UI
- [ ] Multiplayer support
- [ ] Tournament mode
- [ ] Leaderboards

---

## License

MIT License - See [LICENSE](LICENSE) file for details.

---

## Credits

**Original Implementation**: Milad (2024)
**Refactored Package**: Milad with Claude Code (2026)

**Algorithm Inspiration**:
- Temporal Difference Learning (Sutton & Barto, 2018)
- Adversarial Training in Games (Silver et al., AlphaGo)
- Linear Function Approximation in RL

---

## Contact & Support

- **Issues**: [GitHub Issues](https://github.com/yourusername/PacMan-Zombie/issues)
- **Discussions**: [GitHub Discussions](https://github.com/yourusername/PacMan-Zombie/discussions)

---

## Changelog

### Version 2.0 (2026-01-01) - Complete Refactoring
- âœ¨ Professional Python package structure
- âœ¨ Terminal-based playable game
- âœ¨ Complete training system with CLI
- âœ¨ JSON weight format with metadata
- âœ¨ Comprehensive documentation
- âœ¨ Type hints throughout
- ðŸ“¦ Preserved exact original algorithms

### Version 1.0 (2024) - Original Implementation
- Initial prototype with Pygame
- Basic training scripts
- Text-based weight files

---

**Ready to battle the zombies? Start playing now!** ðŸŸ¡ðŸ§Ÿ

```bash
python scripts/play.py
```
